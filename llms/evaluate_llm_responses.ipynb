{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import prompts\n",
    "import evaluation\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "sys.path.append('../')\n",
    "import post_processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>exertion_points</th>\n",
       "      <th>step_goal</th>\n",
       "      <th>minutes_below_zone_1</th>\n",
       "      <th>minutes_in_zone_1</th>\n",
       "      <th>steps</th>\n",
       "      <th>very_active_minutes</th>\n",
       "      <th>minutes_in_zone_2</th>\n",
       "      <th>minutes_in_zone_3</th>\n",
       "      <th>altitude</th>\n",
       "      <th>lightly_active_minutes</th>\n",
       "      <th>moderately_active_minutes</th>\n",
       "      <th>sedentary_minutes</th>\n",
       "      <th>exercises</th>\n",
       "      <th>exercise_duration</th>\n",
       "      <th>sleep_points</th>\n",
       "      <th>sleep_duration</th>\n",
       "      <th>calories</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>621e2e8e67b776a24055b564</td>\n",
       "      <td>2021-05-24 00:00:00</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1349.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>713.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.967</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>621e2e8e67b776a24055b564</td>\n",
       "      <td>2021-05-24 01:00:00</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1349.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>713.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.967</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                date  exertion_points  step_goal  \\\n",
       "0  621e2e8e67b776a24055b564 2021-05-24 00:00:00             27.0        0.0   \n",
       "1  621e2e8e67b776a24055b564 2021-05-24 01:00:00             27.0        0.0   \n",
       "\n",
       "   minutes_below_zone_1  minutes_in_zone_1  steps  very_active_minutes  \\\n",
       "0                1349.0               83.0   99.0                 33.0   \n",
       "1                1349.0               83.0    0.0                 33.0   \n",
       "\n",
       "   minutes_in_zone_2  minutes_in_zone_3  altitude  lightly_active_minutes  \\\n",
       "0                0.0                0.0       0.0                   149.0   \n",
       "1                0.0                0.0       0.0                   149.0   \n",
       "\n",
       "   moderately_active_minutes  sedentary_minutes  exercises  exercise_duration  \\\n",
       "0                       24.0              713.0          2              0.967   \n",
       "1                       24.0              713.0          2              0.967   \n",
       "\n",
       "   sleep_points  sleep_duration  calories  cluster  \n",
       "0          25.0             0.0     16.82        1  \n",
       "1          25.0             0.0      2.29        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = post_processing.load_data()\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instances and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instances\n",
    "instances_interpret = [27606, 15179, 29493, 19985, 3144, 19966, 945, 6368, 18524, 30216, 13578, 13400, 5213, 2855, 9869, 15183, 13296, 15463, 19307, 4658]\n",
    "example_instances = [17170, 570]\n",
    "# parameteres for the data\n",
    "granularity = 'hourly'\n",
    "# parameteres for the ML component\n",
    "ml_task = 'clustering'\n",
    "real_task = 'well-being'\n",
    "target = 'cluster'\n",
    "target_encoding = {0: 'negative', 1: 'positive'}\n",
    "# parameteres for the XAI component\n",
    "scope = 'local'\n",
    "xai_method = 'lime'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM parameters\n",
    "model = 'mistral'\n",
    "learning = 'few'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing instances:  10%|█         | 2/20 [00:43<06:28, 21.57s/inst]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance 29493 has not a user response\n",
      "Instance 29493 has not a developer response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing instances: 100%|██████████| 20/20 [28:10<00:00, 84.54s/inst] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mistral  in  few -shot learning: \n",
      "Avg coherence: 0.7140676661541587\n",
      "Avg number of grammatical errors: 0.7368421052631579\n",
      "Avg ARI: 50.382810217856324\n",
      "Avg sentiment consistency: 0.20196744421944168\n",
      "Avg percentage of concepts covered: 0.37372843874391865\n",
      "Avg percentage of new concepts introduced: 0.5959171444205982\n",
      "Avg spearman rank correlation: 0.7463044905277404\n",
      "Avg NDCG differences: 0.012097979504638453\n",
      "Avg euclidean distances: 0.20424991864383735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize the metrics\n",
    "coherences, grammaticals, readabilities, sentiments, conc_covs, conc_intrs, spearman_corrs, ndcg_difs, eucl_dists = [], [], [], [], [], [], [], [], []\n",
    "pbar = tqdm(total=len(instances_interpret), desc=\"Processing instances\", unit=\"inst\")\n",
    "for instance in instances_interpret:  # for all the instances to interpret\n",
    "    # ------------ STRUCTURAL EVALUATION ------------ #\n",
    "    try:  # because we might do not have the user response for all the instances\n",
    "\n",
    "        # read the user response\n",
    "        with open(f'../data/llms_output/{model}_{learning}/{instance}_user.txt', 'r') as f: \n",
    "            user_response = f.read()\n",
    "\n",
    "        # create the prompt\n",
    "        if learning == 'zero':\n",
    "            query = prompts.zero_prompt(data, instance, target, target_encoding, granularity, real_task)\n",
    "        elif learning == 'one':\n",
    "            query = prompts.one_prompt(data, instance, example_instances[0], target, target_encoding, granularity, real_task)\n",
    "        elif learning == 'few':\n",
    "            query = prompts.few_prompt(data, instance, example_instances, target, target_encoding, granularity, real_task)\n",
    "\n",
    "        # structural metrics\n",
    "        coherence, grammatical, readability, sentiment, coverage, concepts = evaluation.structural_quality_evaluation(query, user_response)\n",
    "        coherences.append(coherence)\n",
    "        grammaticals.append(grammatical)\n",
    "        readabilities.append(readability)\n",
    "        sentiments.append(sentiment)\n",
    "        conc_covs.append(coverage)\n",
    "        conc_intrs.append(concepts)      \n",
    "    except:\n",
    "        print(f'Instance {instance} has not a user response')\n",
    "\n",
    "    # ------------ CONTENT EVALUATION ------------ #\n",
    "    try: # because we might do not have the user response for all the instances\n",
    "        # read the developer response\n",
    "        with open(f'../data/llms_output/{model}_{learning}/{instance}_developer.json', 'r') as f:\n",
    "            llm_response = json.load(f)\n",
    "\n",
    "        # content metrics\n",
    "        spearman_corr, ndcg_dif, eucl_dist = evaluation.content_xai_quality_evaluation(instance, llm_response)\n",
    "        spearman_corrs.append(spearman_corr)\n",
    "        ndcg_difs.append(ndcg_dif)\n",
    "        eucl_dists.append(eucl_dist)\n",
    "    except:\n",
    "        print(f'Instance {instance} has not a developer response')\n",
    "    pbar.update(1) \n",
    "pbar.close()\n",
    "\n",
    "# print the results\n",
    "evaluation.aggregated_evaluation(model, learning, coherences, grammaticals, readabilities, sentiments, conc_covs, conc_intrs, spearman_corrs, ndcg_difs, eucl_dists)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
